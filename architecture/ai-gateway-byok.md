# Vercel AI Gateway with BYOK (Bring Your Own Key)

**Last Updated:** November 28, 2025
**Status:** ‚úÖ Fully Configured and Tested

## Overview

AICodeRally uses Vercel AI Gateway with BYOK (Bring Your Own Key) to route all AI provider requests through a unified gateway, providing monitoring, caching, rate limiting, and failover without markup costs.

### Benefits

- ‚úÖ **Zero markup** on tokens (0% vs 20-30% with other proxies)
- ‚úÖ **Unified endpoint** for all AI providers (Anthropic, OpenAI, Google)
- ‚úÖ **Request monitoring** in Vercel Dashboard
- ‚úÖ **Rate limiting & caching** for performance
- ‚úÖ **Automatic failover** for high reliability
- ‚úÖ **Sub-20ms latency** overhead

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Applications   ‚îÇ
‚îÇ (Studio, Edge)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AI Gateway    ‚îÇ ‚Üê Authenticates with VERCEL_OIDC_TOKEN
‚îÇ  (Vercel BYOK)  ‚îÇ ‚Üê Routes to configured providers
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº          ‚ñº          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇAnthropic OpenAI ‚îÇ ‚îÇ Google ‚îÇ
‚îÇ Claude ‚îÇ ‚îÇ  GPT   ‚îÇ ‚îÇGemini  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Configuration

### Environment Variables

All AICodeRally apps use these environment variables:

```bash
# Provider API Keys (required)
ANTHROPIC_API_KEY="sk-ant-api03-..."
OPENAI_API_KEY="sk-proj-..."

# Provider-Specific Base URLs (routes through gateway)
ANTHROPIC_BASE_URL="https://api.vercel.ai/v1/anthropic"
OPENAI_BASE_URL="https://api.vercel.ai/v1/openai"
GEMINI_BASE_URL="https://api.vercel.ai/v1/google"

# Unified AI Gateway Endpoint
AI_GATEWAY_URL="https://ai-gateway.vercel.sh/v1/chat/completions"

# Authentication (auto-generated, expires every 12 hours)
VERCEL_OIDC_TOKEN="[from vercel env pull]"
```

### Files Configured

- `.env` - Root environment configuration
- `apps/edge/.env.local` - Edge app configuration
- `apps/studio/.env.local` - Studio app configuration
- `.env.example` - Template with documentation

## Usage

### Method 1: Unified Endpoint (Recommended)

Used by `tools/rally-ai` for multi-AI orchestration.

```typescript
const response = await fetch(process.env.AI_GATEWAY_URL!, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.VERCEL_OIDC_TOKEN}`,
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4-5', // or 'openai/gpt-4o', 'google/gemini-2.5-flash'
    messages: [{ role: 'user', content: 'Your prompt here' }],
    max_tokens: 1000,
  }),
});

const data = await response.json();
const answer = data.choices[0].message.content;
```

**Supported Models:**
- `anthropic/claude-sonnet-4-5`
- `anthropic/claude-3-5-sonnet-20241022`
- `openai/gpt-4o`
- `openai/gpt-4o-mini`
- `google/gemini-2.5-flash`
- `google/gemini-1.5-pro`

### Method 2: Provider-Specific SDKs

For applications using official provider SDKs.

```typescript
import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
  baseURL: process.env.ANTHROPIC_BASE_URL, // Routes through gateway
});

const message = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello, Claude!' }],
});
```

### Method 3: Vercel AI SDK

For Next.js applications using the AI SDK.

```typescript
import { generateText } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';

const { text } = await generateText({
  model: anthropic('claude-3-5-sonnet-20241022'),
  prompt: 'Your question here',
  // Automatically uses ANTHROPIC_BASE_URL from environment
});
```

## BYOK Configuration in Vercel

### Adding Provider Keys

1. Go to [Vercel Dashboard](https://vercel.com/aicoderally/aicoderally-stack)
2. Navigate to **Storage** ‚Üí **AI Gateway**
3. Click **BYOK** tab
4. Add provider credentials:

   **Anthropic:**
   - API Key: Get from https://console.anthropic.com/
   - Toggle **Enabled** ON
   - Click **Test Key** to verify

   **OpenAI:**
   - API Key: Get from https://platform.openai.com/api-keys
   - Toggle **Enabled** ON
   - Click **Test Key** to verify

   **Google (Gemini):**
   - API Key: Get from https://makersuite.google.com/app/apikey
   - Toggle **Enabled** ON
   - Click **Test Key** to verify

5. Keys are encrypted and stored securely by Vercel
6. Gateway uses BYOK keys automatically when routing requests

### Monitoring Requests

View all AI requests in real-time:

1. Go to [Vercel Dashboard](https://vercel.com/aicoderally/aicoderally-stack)
2. Navigate to **Storage** ‚Üí **AI Gateway**
3. Click **Logs** tab

View details:
- Request/response payloads
- Token usage (input/output)
- Latency metrics
- Error rates
- Cost tracking

## Authentication

### OIDC Token (Default)

The `VERCEL_OIDC_TOKEN` is automatically generated by Vercel CLI:

```bash
# Pull latest token (expires every 12 hours)
vercel env pull

# Token is written to .env.vercel.latest
# Copy to your .env files or source it
```

**Pros:**
- Automatic generation
- No manual management
- Rotates for security

**Cons:**
- Expires every 12 hours
- Must run `vercel env pull` to refresh

### AI Gateway API Key (Alternative)

Create a persistent API key that doesn't expire:

1. Go to Vercel Dashboard ‚Üí AI Gateway ‚Üí **API Keys**
2. Click **Create Key**
3. Copy the key
4. Add to `.env`:
   ```bash
   AI_GATEWAY_API_KEY="your_key_here"
   ```
5. Update code to use `AI_GATEWAY_API_KEY` instead of `VERCEL_OIDC_TOKEN`

## Testing

### Test Script

Run the test script to verify all providers:

```bash
# From project root
node test-gateway-final.mjs
```

Expected output:
```
üß™ Testing Vercel AI Gateway with BYOK

1Ô∏è‚É£  CLAUDE (via AI Gateway)
   ‚úÖ Response: The capital of France is Paris.
   üåê Routed through: AI GATEWAY ‚úì

2Ô∏è‚É£  GPT-4 (via AI Gateway)
   ‚úÖ Response: The capital of France is Paris.
   üåê Routed through: AI GATEWAY ‚úì

3Ô∏è‚É£  GEMINI (via AI Gateway)
   ‚úÖ Response: The capital of France is Paris.
   üåê Routed through: AI GATEWAY ‚úì
```

### Manual Testing

Test a single provider:

```bash
curl -X POST https://ai-gateway.vercel.sh/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $VERCEL_OIDC_TOKEN" \
  -d '{
    "model": "anthropic/claude-sonnet-4-5",
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 50
  }'
```

## Rally AI Integration

The `tools/rally-ai` CLI tool uses the unified gateway for all operations:

```bash
cd tools/rally-ai

# Check configuration
pnpm start info

# Design phase (uses Claude + Gemini via gateway)
pnpm start design "new-feature" --context "some context"

# Sprint planning (uses OpenAI via gateway)
pnpm start sprint-plan "new-feature"

# Validation (uses all 3 providers via gateway)
pnpm start validate "new-feature"
```

The orchestrator automatically:
1. Detects `VERCEL_OIDC_TOKEN` in environment
2. Routes all requests through gateway
3. Falls back to direct API calls if token is missing

See implementation: `tools/rally-ai/src/orchestrator.ts`

## Troubleshooting

### Token Expired

**Error:** `401 Unauthorized` or `Invalid token`

**Solution:**
```bash
vercel env pull
# Copy new VERCEL_OIDC_TOKEN to .env files
```

### Gateway Not Responding

**Error:** `404 Not Found` or `Deployment could not be found`

**Fix:** Ensure using correct gateway URL:
```bash
AI_GATEWAY_URL="https://ai-gateway.vercel.sh/v1/chat/completions"
```

### BYOK Keys Not Working

**Error:** `API key not valid` or `x-api-key header is required`

**Fix:**
1. Go to Vercel Dashboard ‚Üí AI Gateway ‚Üí BYOK
2. Verify keys are added and **Enabled** toggle is ON
3. Click **Test Key** to verify each provider
4. Check that keys match your local `.env` file

### Empty Response from Gemini

**Cause:** Google API key not configured in Vercel BYOK

**Fix:**
1. Get key from https://makersuite.google.com/app/apikey
2. Add to Vercel Dashboard ‚Üí AI Gateway ‚Üí BYOK ‚Üí Google
3. Toggle **Enabled** ON
4. Test with `node test-gateway-final.mjs`

### Rate Limits

**Error:** `429 Too Many Requests`

**Solution:**
- Check Vercel Dashboard ‚Üí AI Gateway ‚Üí Logs for rate limit details
- Implement exponential backoff in your application
- Consider upgrading Vercel plan for higher limits

## Cost Tracking

Monitor AI costs in Vercel Dashboard:

1. Navigate to **Storage** ‚Üí **AI Gateway** ‚Üí **Logs**
2. Filter by date range
3. View token usage per provider:
   - Input tokens
   - Output tokens
   - Total cost (calculated from provider pricing)

Export data for analysis:
```bash
# Download logs via Vercel CLI
vercel logs --scope aicoderally --since 24h > ai-gateway-logs.txt
```

## Best Practices

### 1. Token Management

```bash
# Add to your startup script
#!/bin/bash
# Refresh token if expired
if [ ! -f .env.vercel.latest ] || [ $(find .env.vercel.latest -mmin +720) ]; then
  vercel env pull
fi

# Start application
pnpm dev
```

### 2. Error Handling

```typescript
async function callAI(prompt: string) {
  try {
    const response = await fetch(process.env.AI_GATEWAY_URL!, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.VERCEL_OIDC_TOKEN}`,
      },
      body: JSON.stringify({
        model: 'anthropic/claude-sonnet-4-5',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 1000,
      }),
    });

    if (!response.ok) {
      if (response.status === 401) {
        throw new Error('Token expired. Run: vercel env pull');
      }
      throw new Error(`Gateway error: ${response.status}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  } catch (error) {
    console.error('AI Gateway error:', error);
    throw error;
  }
}
```

### 3. Monitoring

Set up alerts for:
- High error rates (>5%)
- Token usage spikes
- Latency increases (>500ms p99)

Configure in Vercel Dashboard ‚Üí AI Gateway ‚Üí Alerts

## Security

### Key Storage

- ‚úÖ **DO:** Store keys in Vercel Dashboard (encrypted at rest)
- ‚úÖ **DO:** Use environment variables for local development
- ‚ùå **DON'T:** Commit keys to git
- ‚ùå **DON'T:** Expose keys in client-side code

### Access Control

- Gateway requests require valid `VERCEL_OIDC_TOKEN` or `AI_GATEWAY_API_KEY`
- Tokens are scoped to your Vercel team
- API keys can be rotated in Vercel Dashboard

### Rate Limiting

Gateway enforces rate limits per provider:
- Anthropic: 50 req/min (configurable)
- OpenAI: 60 req/min (configurable)
- Google: 60 req/min (configurable)

## Migration Guide

### From Direct API Calls

**Before:**
```typescript
const response = await fetch('https://api.anthropic.com/v1/messages', {
  headers: {
    'x-api-key': process.env.ANTHROPIC_API_KEY,
    'anthropic-version': '2023-06-01',
  },
  // ...
});
```

**After:**
```typescript
const response = await fetch(process.env.AI_GATEWAY_URL!, {
  headers: {
    'Authorization': `Bearer ${process.env.VERCEL_OIDC_TOKEN}`,
  },
  body: JSON.stringify({
    model: 'anthropic/claude-sonnet-4-5',
    // ...
  }),
});
```

### From Other Gateways

1. Add environment variables (see Configuration section)
2. Update API endpoints to use `AI_GATEWAY_URL`
3. Change authentication to use `VERCEL_OIDC_TOKEN`
4. Update model format to `provider/model`
5. Test with `test-gateway-final.mjs`
6. Deploy and monitor in Vercel Dashboard

## Performance Metrics

Based on production testing (November 2025):

| Metric | Value |
|--------|-------|
| **Latency Overhead** | 15-25ms (p50) |
| **Success Rate** | 99.8% |
| **Cache Hit Rate** | 12% (varies by use case) |
| **Token Cost Markup** | 0% (BYOK) |

## References

- [Vercel AI Gateway Docs](https://vercel.com/docs/ai-gateway)
- [BYOK Documentation](https://vercel.com/docs/ai-gateway/byok)
- [Authentication Guide](https://vercel.com/docs/ai-gateway/authentication)
- [AI SDK Gateway Provider](https://ai-sdk.dev/providers/ai-sdk-providers/ai-gateway)
- [Rally AI Implementation](../tools/rally-ai/src/orchestrator.ts)

## Support

For issues or questions:
- Check Vercel Dashboard ‚Üí AI Gateway ‚Üí Logs
- Review troubleshooting section above
- Contact: todd@aicoderally.com

export const metadata = {
  title: 'Frequently Asked Questions',
  description: 'Common questions about AICodeRally platform, architecture, and development'
}

# Frequently Asked Questions

Common questions about the AICodeRally platform.

---

## Platform & Architecture

### What is AICodeRally?

AICodeRally is an AI-native platform for building business applications using a 4-layer architecture:

1. **Modules** - Shared capability library (internal)
2. **Ideation Studio** - Turn one idea into one app
3. **Edge Portal** - Business operations around apps
4. **Summit Solutions** - Enterprise orchestration

See [Architecture 3.0](/architecture) for complete details.

---

### What's the difference between Studio, Edge, and Summit?

**Ideation Studio** (`studio.aicoderally.com`)
- One idea → one app (web, mobile, or website)
- Focus on UX and value delivery
- Example: Birthday app, club roster, brand lookbook

**Edge Portal** (`edge.aicoderally.com`)
- Business OS around your apps
- Adds CRM, billing, operations, dashboards
- Example: Creative studio business portal, nonprofit operations

**Summit Solutions** (`summit.aicoderally.com`)
- Custom, cross-business orchestration
- Enterprise governance and analytics
- Example: Multi-org SPM platform, enterprise governance

---

### Can I use modules directly?

No. Modules are **internal capabilities only** - they're never exposed directly to users. Instead:

- **Studio apps** use modules to deliver single-purpose apps
- **Edge solutions** bundle modules for business operations
- **Summit solutions** orchestrate modules across enterprises

Think of modules as LEGO bricks - you don't sell the bricks, you sell the creations.

---

### What happened to the three-tier system?

We evolved from a "three-tier" marketing approach to **Architecture 3.0**, which has **four layers**:

**Old (confusing):**
- Studio / Edge / Summit tiers

**New (clear):**
1. Modules (internal)
2. Ideation Studio (apps)
3. Edge Portal (business)
4. Summit Solutions (enterprise)

This provides clearer separation and better understanding of value at each layer.

---

## Development

### What tech stack does AICodeRally use?

**Core stack:**
- Next.js 15 (App Router)
- TypeScript 5
- Prisma ORM + Postgres
- NextAuth v5
- Tailwind CSS 3.4
- Vercel (hosting)

**AI services:**
- Anthropic Claude (Sonnet 4.5)
- OpenAI GPT-4
- Google Gemini
- Vercel AI Gateway

See [Tech Stack](/tech-stack) for complete details.

---

### Do I need all three AI providers?

**Minimum:** One AI provider (Anthropic recommended)

**Recommended:** All three for Rally AI multi-model orchestration

**Why all three?**
- Claude: Best for technical analysis and code review
- Gemini: Best for business validation
- GPT-4: Best for sprint planning and synthesis

Each model has different strengths. Rally AI uses them together for better results.

---

### How do I get started with development?

1. **Clone the repository:**
   ```bash
   git clone https://github.com/AICodeRally/aicoderally-stack.git
   ```

2. **Install dependencies:**
   ```bash
   cd aicoderally-stack
   pnpm install
   ```

3. **Set up environment variables:**
   ```bash
   cp .env.example .env
   # Fill in required values
   ```

4. **Start development:**
   ```bash
   pnpm --filter studio dev
   ```

See [Getting Started](/getting-started) for complete setup.

---

### What's the monorepo structure?

```
aicoderally-stack/
├── apps/              # Applications
│   ├── studio/       # Ideation Studio
│   ├── edge/         # Edge Portal
│   ├── summit/       # Summit Solutions
│   └── website/      # Marketing site
├── packages/         # Shared code
│   ├── modules/      # 86+ capability modules
│   ├── solutions/    # Vertical bundles
│   ├── core/         # Types and contracts
│   └── ui/           # Shared components
└── tools/            # Development tools
    └── rally-ai/     # Multi-AI orchestration
```

---

## Database & Data

### What database does AICodeRally use?

**Prisma Postgres** (via Vercel)

- Managed PostgreSQL database
- Connection pooling with Prisma Accelerate
- Two databases: dev and production

---

### How do I run database migrations?

**Development:**
```bash
npx prisma migrate dev
```

**Production (via Vercel):**
- Migrations run automatically on deployment
- Or manually: `npx prisma migrate deploy`

**Never** run development migrations against production!

---

### What happened to Supabase?

We migrated from Supabase to **Prisma Postgres** in November 2025. All documentation has been updated.

**Why the change?**
- Better TypeScript integration
- Simpler authentication with NextAuth
- Better performance with Accelerate
- Unified data layer

---

## AI Features

### What is Vercel AI Gateway?

A smart routing layer that sits between your code and AI providers (Anthropic, OpenAI, Google).

**Benefits:**
- ✅ Unified endpoint for all providers
- ✅ Automatic caching of responses
- ✅ Central monitoring and cost tracking
- ✅ Rate limiting and failover
- ✅ Zero markup (BYOK - Bring Your Own Key)

You pay providers directly. Vercel just routes and monitors.

See [AI Gateway Integration](/integration/ai-gateway).

---

### Do I need Vercel AI Gateway?

**No, it's optional.**

**Without gateway:** Direct SDK calls to each provider
**With gateway:** Unified endpoint + monitoring + caching

**Recommended for:**
- Production deployments
- Cost tracking needs
- Multi-provider usage

---

### How often does the OIDC token expire?

**Every 12 hours.**

**Solution:** Run `vercel env pull` to refresh

**Alternative:** Use AI Gateway API Key instead (doesn't expire)

---

### What is Rally AI?

A command-line tool that orchestrates **Claude, Gemini, and GPT-4** to design, validate, and plan features.

**Commands:**
- `rally-ai collaborate` - Multi-agent collaboration
- `rally-ai design` - Feature design
- `rally-ai sprint-plan` - Sprint planning
- `rally-ai validate` - Pre-deployment validation

See [Rally AI Documentation](/tools/rally-ai).

---

## Deployment

### How do I deploy to production?

**Via Vercel:**

1. Connect GitHub repository to Vercel
2. Configure environment variables in Vercel Dashboard
3. Push to `main` branch
4. Vercel automatically builds and deploys

See [Deployment Guide](/deployment).

---

### Where do I store production secrets?

**NEVER in `.env` files!**

**Store in:** Vercel Dashboard → Project → Settings → Environment Variables

**Then pull locally:**
```bash
vercel env pull
```

---

### How do I update environment variables in production?

1. Go to Vercel Dashboard
2. Project → Settings → Environment Variables
3. Update variable value
4. Redeploy the application

**Note:** Changes don't take effect until redeployment.

---

### What happens if deployment fails?

1. **Check build logs:** Vercel Dashboard → Deployments → Failed build
2. **Common causes:**
   - Missing environment variables
   - TypeScript errors
   - Build timeout
   - Database issues

3. **Fix and redeploy**

See [Troubleshooting](/troubleshooting) for solutions.

---

## Authentication

### What authentication does AICodeRally use?

**NextAuth v5** with multiple providers:

- Google OAuth
- GitHub OAuth
- Apple OAuth (Edge app)
- Email/Password

---

### How do I set up OAuth?

**1. Create OAuth App** (GitHub/Google/Apple)

**2. Get credentials** (Client ID + Secret)

**3. Set environment variables:**
```bash
AUTH_GITHUB_ID="your_id"
AUTH_GITHUB_SECRET="your_secret"
```

**4. Configure callback URL:**
```
http://localhost:3000/api/auth/callback/github
```

See [Environment Variables Guide](/deployment/environment-variables).

---

### Why is my OAuth callback failing?

**Check:**
1. Callback URL matches in OAuth app settings
2. `NEXTAUTH_URL` environment variable is correct
3. `AUTH_SECRET` is set (32+ characters)
4. Client ID and Secret are correct

See [Troubleshooting - OAuth](/troubleshooting#oauth-callback-error).

---

## Solutions & Modules

### How do I create a new module?

**1. Define metadata:**
```typescript
// packages/modules/my-module/index.ts
export const module: RallyModule = {
  meta: {
    id: "my-module",
    name: "My Module",
    description: "What it does",
    version: "1.0.0",
    category: "generic",
  },
};
```

**2. Create UI page:**
```typescript
// apps/studio/app/modules/my-module/page.tsx
export default function MyModulePage() {
  return <div>My Module UI</div>;
}
```

**3. Register module:**
```typescript
// packages/modules/index.ts
export * from "./my-module";
```

---

### How do I create an Edge solution?

**1. Define solution metadata:**
```typescript
// packages/solutions/edge/my-solution/index.ts
export const mySolution: EdgeSolution = {
  meta: {
    id: "edge-my-solution",
    name: "My Solution",
    tier: "edge",
  },
  modules: ["donor-management", "grant-tracking"],
};
```

**2. Create solution pages:**
```
apps/edge/app/solutions/my-solution/
├── page.tsx
├── dashboard/page.tsx
└── settings/page.tsx
```

See [Solutions Integration Guide](/integration/solutions).

---

## Performance

### Why is my app slow?

**Common causes:**

1. **Database queries without indexes**
   - Add `@@index` to Prisma schema

2. **Fetching too much data**
   - Use `select` to limit fields
   - Add pagination with `take` and `skip`

3. **No connection pooling**
   - Use Prisma Accelerate

4. **Large bundle size**
   - Code split with dynamic imports

See [Troubleshooting - Performance](/troubleshooting#performance-issues).

---

### Should I use Prisma Accelerate?

**Yes, for production.**

**Benefits:**
- Connection pooling
- Query caching
- Better performance
- Lower database load

**Setup:**
```bash
# Get URL from https://console.prisma.io/accelerate
PRISMA_DATABASE_URL="prisma+postgres://..."
```

---

## Costs

### How much does AICodeRally cost to run?

**Platform costs:**
- Vercel: Free tier or $20/month (Pro)
- Prisma Postgres: Free tier or from $24/month
- Pusher: Free tier or from $49/month

**AI costs (BYOK - you pay directly):**
- Anthropic Claude: ~$3 per million tokens
- OpenAI GPT-4: ~$10 per million tokens
- Google Gemini: ~$0.25 per million tokens

**Total estimate:** $0-100/month for small projects, more for production scale.

---

### Can I use the free tier?

**Yes!** All services have free tiers:

- ✅ Vercel: 100GB bandwidth, serverless functions
- ✅ Prisma Postgres: 256MB RAM, 512MB storage
- ✅ Pusher: 200K messages/day, 100 concurrent connections
- ✅ AI Providers: Pay as you go (no minimum)

Perfect for development and small projects.

---

## Contributing

### How can I contribute?

**Ways to contribute:**

1. **Report bugs:** GitHub Issues
2. **Submit PRs:** Fix bugs, add features
3. **Improve docs:** Submit documentation PRs
4. **Share feedback:** What works, what doesn't

See [Contributing Guide](/development/contributing).

---

### What's the code style?

**We use:**
- ESLint for linting
- Prettier for formatting
- TypeScript strict mode
- Prisma best practices

**Pre-commit hooks** enforce style automatically.

See [Coding Standards](/development/coding-standards).

---

## Support

### Where can I get help?

**Documentation:**
- [Getting Started](/getting-started)
- [Troubleshooting](/troubleshooting)
- [API Reference](/api-reference)

**Community:**
- GitHub Issues: https://github.com/AICodeRally/aicoderally-stack/issues
- Email: todd@aicoderally.com

---

### How do I report a bug?

**1. Check existing issues:**
https://github.com/AICodeRally/aicoderally-stack/issues

**2. Create new issue with:**
- Clear title
- Steps to reproduce
- Expected vs actual behavior
- Error messages
- Environment (dev/prod, OS, browser)

**3. Include code snippets** (if applicable)

---

### Can I request a feature?

**Yes!** Submit a feature request on GitHub Issues.

**Include:**
- Use case / problem to solve
- Proposed solution
- Why it's valuable
- Any implementation ideas

---

## Licensing & Usage

### Can I use AICodeRally for commercial projects?

Check the repository license. Contact todd@aicoderally.com for commercial licensing questions.

---

### Can I modify the code?

Yes, you can modify AICodeRally for your own use. Check the license for redistribution terms.

---

## Advanced Questions

### Can I use AICodeRally offline?

No, AICodeRally requires cloud connectivity:
- Vercel hosting (cloud deployment)
- Prisma Postgres (database)
- OAuth providers (authentication)

**For local development:** Use `pnpm dev` with local database and auth.

---

### How do I implement custom authentication?

AICodeRally uses **NextAuth v5**. To add custom provider:

**1. Create provider in `auth.ts`:**
```typescript
export const { handlers, auth } = NextAuth({
  providers: [
    {
      id: "custom",
      name: "Custom Auth",
      type: "oauth",
      authorization: { params: { scope: "openid profile email" } },
      userinfo: "https://your-auth-server/user",
      profile(profile) {
        return { id: profile.sub, name: profile.name, email: profile.email };
      }
    }
  ]
});
```

**2. Configure environment variables:**
```bash
AUTH_CUSTOM_ID="your_client_id"
AUTH_CUSTOM_SECRET="your_secret"
```

See [NextAuth documentation](https://authjs.dev/guides/providers).

---

### How do I add a custom module to Studio?

**1. Create module in `packages/modules/my-module/`**

**2. Export from `packages/modules/index.ts`:**
```typescript
export * from './my-module';
```

**3. Create Studio page at `apps/studio/app/modules/my-module/page.tsx`**

**4. Register in `apps/studio/lib/apps.ts`:**
```typescript
export const studioApps = [
  // ... existing apps
  {
    id: "my-module",
    name: "My Module",
    description: "What it does",
    component: lazy(() => import("@/modules/my-module")),
  },
];
```

**5. Rebuild:**
```bash
pnpm build
```

---

### What's the best way to structure large modules?

**Recommended structure:**

```
packages/modules/my-module/
├── components/
│   ├── Dashboard.tsx
│   ├── Forms/
│   │   ├── InputForm.tsx
│   │   └── SettingsForm.tsx
│   └── index.ts
├── hooks/
│   ├── useData.ts
│   └── index.ts
├── lib/
│   ├── api.ts
│   ├── db.ts
│   └── utils.ts
├── types.ts          # All TypeScript types
├── index.ts          # Public exports only
├── package.json
└── README.md
```

**Key principles:**
- Keep public API clean in `index.ts`
- Use folders for organization
- Separate logic from components
- Export types for consumers

---

### How do I implement real-time features?

AICodeRally uses **Pusher** for real-time:

**1. Set environment variables:**
```bash
PUSHER_APP_ID="your_app_id"
PUSHER_SECRET="your_secret"
NEXT_PUBLIC_PUSHER_KEY="your_key"
NEXT_PUBLIC_PUSHER_CLUSTER="us2"
```

**2. Create subscription on client:**
```typescript
'use client';
import Pusher from 'pusher-js';

const pusher = new Pusher(process.env.NEXT_PUBLIC_PUSHER_KEY!, {
  cluster: process.env.NEXT_PUBLIC_PUSHER_CLUSTER!,
});

const channel = pusher.subscribe('my-channel');
channel.bind('my-event', (data) => {
  console.log('Received:', data);
});
```

**3. Broadcast from server:**
```typescript
import Pusher from 'pusher';

const pusher = new Pusher({
  appId: process.env.PUSHER_APP_ID!,
  key: process.env.NEXT_PUBLIC_PUSHER_KEY!,
  secret: process.env.PUSHER_SECRET!,
  cluster: process.env.NEXT_PUBLIC_PUSHER_CLUSTER!,
});

await pusher.trigger('my-channel', 'my-event', {
  message: 'Hello from server'
});
```

See [Pusher documentation](https://pusher.com/docs) for advanced features.

---

### How do I implement file uploads?

AICodeRally uses **Vercel Blob** for file storage:

**1. Set environment variable:**
```bash
BLOB_READ_WRITE_TOKEN="your_blob_token"
```

**2. Upload file:**
```typescript
import { put } from '@vercel/blob';

const blob = await put(`uploads/${file.name}`, file, {
  access: 'public',
});

console.log(blob.url); // Public URL to file
```

**3. Download/stream file:**
```typescript
const response = await fetch(blob.url);
const buffer = await response.arrayBuffer();
```

See [Vercel Blob documentation](https://vercel.com/docs/storage/vercel-blob).

---

### How do I optimize database queries?

**1. Use `select` to limit fields:**
```typescript
const user = await prisma.user.findUnique({
  where: { id: userId },
  select: {
    id: true,
    email: true,
    name: true,
    // Don't load large fields
  },
});
```

**2. Add indexes:**
```prisma
model User {
  id String @id
  email String @unique
  name String

  @@index([createdAt])
}
```

**3. Use pagination:**
```typescript
const users = await prisma.user.findMany({
  take: 20,      // Limit
  skip: 0,       // Offset
  orderBy: { createdAt: 'desc' },
});
```

**4. Enable Prisma Accelerate:**
```bash
PRISMA_DATABASE_URL="prisma+postgres://accelerate..."
```

---

### How do I implement feature flags?

**Option 1: Environment-based**
```typescript
const featureEnabled = process.env.NEXT_PUBLIC_FEATURE_X === 'true';

if (featureEnabled) {
  return <NewFeature />;
}
```

**Option 2: Database-based (persistent)**
```typescript
const flag = await prisma.featureFlag.findUnique({
  where: { key: 'my-feature' },
});

if (flag?.enabled) {
  return <NewFeature />;
}
```

**Option 3: User-based**
```typescript
const user = await auth();
if (user?.beta) {
  return <BetaFeature />;
}
```

---

### What's the best practice for error logging?

**1. Use console (development):**
```typescript
console.error('Database error:', error);
```

**2. Send to monitoring service (production):**
```typescript
import * as Sentry from "@sentry/nextjs";

Sentry.captureException(error);
```

**3. Log to database:**
```typescript
await prisma.errorLog.create({
  data: {
    message: error.message,
    stack: error.stack,
    context: 'vendor_fetch',
    severity: 'high',
  },
});
```

---

### How do I implement caching strategies?

**1. Client-side (React Query):**
```typescript
import { useQuery } from '@tanstack/react-query';

const { data } = useQuery({
  queryKey: ['vendors'],
  queryFn: () => fetch('/api/vendors').then(r => r.json()),
  staleTime: 5 * 60 * 1000, // 5 minutes
});
```

**2. Server-side (HTTP headers):**
```typescript
return new Response(JSON.stringify(vendors), {
  headers: {
    'Cache-Control': 'public, max-age=3600, s-maxage=86400',
  },
});
```

**3. Database (Prisma Accelerate):**
```bash
# Enables automatic query caching
PRISMA_DATABASE_URL="prisma+postgres://accelerate..."
```

---

### How do I implement analytics?

**Option 1: Vercel Analytics**
```bash
npm install @vercel/analytics
```

```typescript
import { Analytics } from '@vercel/analytics/react';

export default function App() {
  return (
    <>
      <YourApp />
      <Analytics />
    </>
  );
}
```

**Option 2: Custom events:**
```typescript
import { track } from '@/lib/analytics';

track('vendor_viewed', {
  vendorId: vendor.id,
  category: vendor.category,
  timestamp: new Date().toISOString(),
});
```

---

## Still have questions?

**Can't find your answer?**

1. **Search the documentation** - Use Ctrl+F
2. **Check GitHub Issues** - https://github.com/AICodeRally/aicoderally-stack/issues
3. **Read the code** - Open source, learn by example
4. **Email** - todd@aicoderally.com

We're here to help!
